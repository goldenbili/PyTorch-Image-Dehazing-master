{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AOD-Net.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "GXKRpUah8_uF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed2045e2-110a-4199-bc93-1a6892b8922d"
      },
      "source": [
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
        " \n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "import getpass\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass()\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}\n",
        " \n",
        " \n",
        "import datetime\n",
        "import json\n",
        "import os\n",
        "import pprint\n",
        "import random\n",
        "import string\n",
        "import sys\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "E: Package 'python-software-properties' has no installation candidate\n",
            "Selecting previously unselected package google-drive-ocamlfuse.\n",
            "(Reading database ... 144865 files and directories currently installed.)\n",
            "Preparing to unpack .../google-drive-ocamlfuse_0.7.23-0ubuntu1~ubuntu18.04.1_amd64.deb ...\n",
            "Unpacking google-drive-ocamlfuse (0.7.23-0ubuntu1~ubuntu18.04.1) ...\n",
            "Setting up google-drive-ocamlfuse (0.7.23-0ubuntu1~ubuntu18.04.1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "··········\n",
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "Please enter the verification code: Access token retrieved correctly.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UkY-4v1ByyXF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        },
        "outputId": "121d371e-0d70-4595-e32f-c03ea6fec036"
      },
      "source": [
        "# memory footprint support libraries/code\n",
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install humanize\n",
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "GPUs = GPU.getGPUs()\n",
        "# XXX: only one GPU on Colab and isn’t guaranteed\n",
        "gpu = GPUs[0]\n",
        "def printm():\n",
        " process = psutil.Process(os.getpid())\n",
        " print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        " print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "printm()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gputil\n",
            "  Downloading https://files.pythonhosted.org/packages/ed/0e/5c61eedde9f6c87713e89d794f01e378cfd9565847d4576fa627d758c554/GPUtil-1.4.0.tar.gz\n",
            "Building wheels for collected packages: gputil\n",
            "  Building wheel for gputil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gputil: filename=GPUtil-1.4.0-cp36-none-any.whl size=7411 sha256=bc9ad2a530cbfc520e82fe3baa82995dfd0291f3616791b672b0d62179bdfdfc\n",
            "  Stored in directory: /root/.cache/pip/wheels/3d/77/07/80562de4bb0786e5ea186911a2c831fdd0018bda69beab71fd\n",
            "Successfully built gputil\n",
            "Installing collected packages: gputil\n",
            "Successfully installed gputil-1.4.0\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (5.4.8)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.6/dist-packages (0.5.1)\n",
            "Gen RAM Free: 12.8 GB  | Proc size: 111.8 MB\n",
            "GPU RAM Free: 15079MB | Used: 0MB | Util   0% | Total 15079MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "guVoesClznIc"
      },
      "source": [
        "import numpy as np\n",
        "from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\n",
        "from keras.layers import Dropout, Flatten, Dense\n",
        "from keras.models import Sequential\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.datasets import cifar10\n",
        "(train_features, train_labels), (test_features, test_labels) = cifar10.load_data()\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(filters=16, kernel_size=(2, 2), padding=\"same\", activation=\"relu\", input_shape=(train_features.shape[1:])))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\n",
        "\n",
        "model.add(Conv2D(filters=32, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\n",
        "\n",
        "model.add(Conv2D(filters=64, kernel_size=(4, 4), padding=\"same\", activation=\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(25600, activation=\"relu\"))\n",
        "model.add(Dense(25600, activation=\"relu\"))\n",
        "model.add(Dense(25600, activation=\"relu\"))\n",
        "model.add(Dense(25600, activation=\"relu\"))\n",
        "model.add(Dense(10, activation=\"softmax\"))\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.fit(train_features, train_labels, validation_split=0.2, epochs=10, batch_size=128, verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6FbTwfyTy71D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc14086d-99bc-4eb0-f80b-8f872e5691c1"
      },
      "source": [
        "!ps ax | grep python"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     48 ?        Sl     0:01 /usr/bin/python2 /usr/local/bin/jupyter-notebook --ip=\"172.28.0.2\" --port=9000 --FileContentsManager.root_dir=\"/\" --LargeFileManager.delete_to_trash=False --MappingKernelManager.root_dir=\"/content\"\n",
            "     55 ?        Ssl    0:02 /usr/bin/python3 -m ipykernel_launcher -f /root/.local/share/jupyter/runtime/kernel-4063b1c8-b0b1-4d48-90a2-3c1408afe65b.json\n",
            "   1871 ?        Zs     0:00 [python3] <defunct>\n",
            "   1884 ?        S      0:00 /bin/bash -c ps ax | grep python\n",
            "   1886 ?        S      0:00 grep python\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CtmF7D_N-8yG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "019cadc2-cb9b-44e5-de7c-c020a160f2db"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wed Dec 16 05:16:45 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 455.45.01    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   39C    P8     9W /  70W |      0MiB / 15079MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZXm1ao7cYHru"
      },
      "source": [
        "!kill -9 -1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5SO8PBsJcsJ6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f934fd9e-7f21-4c01-fdf0-0e31e3726f69"
      },
      "source": [
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P5yq58XEAxVQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a578fd6-5418-4e47-e070-ba0bbc4f9620"
      },
      "source": [
        "import sys\n",
        "\n",
        "!test -d PyTorch-Image-Dehazing-master || git clone https://github.com/goldenbili/PyTorch-Image-Dehazing-master\n",
        "if not 'PyTorch-Image-Dehazing-master' in sys.path:\n",
        "  sys.path += ['PyTorch-Image-Dehazing-master']\n",
        "%cd PyTorch-Image-Dehazing-master/\n",
        "!pwd  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'PyTorch-Image-Dehazing-master'...\n",
            "remote: Enumerating objects: 50, done.\u001b[K\n",
            "remote: Counting objects: 100% (50/50), done.\u001b[K\n",
            "remote: Compressing objects: 100% (50/50), done.\u001b[K\n",
            "remote: Total 50 (delta 28), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (50/50), done.\n",
            "/content/PyTorch-Image-Dehazing-master\n",
            "/content/PyTorch-Image-Dehazing-master\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QW98QfaB8bRp",
        "outputId": "669598d1-4c4d-4a14-881b-2cd1bd8838bf"
      },
      "source": [
        "ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AOD-Net.ipynb  dataloader.py  dehaze.py  LICENSE  net.py  README.md  train.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BDRTN4ZlBpEd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47ac512b-ce9f-4d25-a28f-842255854dc1"
      },
      "source": [
        "!wget http://data.vision.ee.ethz.ch/cvl/DIV2K/DIV2K_train_HR.zip\n",
        "!wget http://data.vision.ee.ethz.ch/cvl/DIV2K/DIV2K_valid_HR.zip\n",
        "!unzip -q DIV2K_train_HR.zip -d data\n",
        "!unzip -q DIV2K_valid_HR.zip -d data\n",
        "!rm DIV2K_train_HR.zip\n",
        "!rm DIV2K_valid_HR.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-12-18 03:40:43--  http://data.vision.ee.ethz.ch/cvl/DIV2K/DIV2K_train_HR.zip\n",
            "Resolving data.vision.ee.ethz.ch (data.vision.ee.ethz.ch)... 129.132.52.162\n",
            "Connecting to data.vision.ee.ethz.ch (data.vision.ee.ethz.ch)|129.132.52.162|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://data.vision.ee.ethz.ch/cvl/DIV2K/DIV2K_train_HR.zip [following]\n",
            "--2020-12-18 03:40:44--  https://data.vision.ee.ethz.ch/cvl/DIV2K/DIV2K_train_HR.zip\n",
            "Connecting to data.vision.ee.ethz.ch (data.vision.ee.ethz.ch)|129.132.52.162|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3530603713 (3.3G) [application/zip]\n",
            "Saving to: ‘DIV2K_train_HR.zip’\n",
            "\n",
            "DIV2K_train_HR.zip    3%[                    ] 132.44M  1.53MB/s    eta 10m 27s"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Vip2CcS7zYw"
      },
      "source": [
        "!rm -r data/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1EQdF0XREXzy"
      },
      "source": [
        "!mkdir ./data\n",
        "!cp ../drive/MyDrive/AOD-Net/original_image.zip ./data/\n",
        "!unzip -q ./data/original_image.zip -d data\n",
        "!rm ./data/original_image.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uL4Iy3TS9hFx"
      },
      "source": [
        "from datetime import datetime\n",
        "now = datetime.now()\n",
        "snapshotPaht = \"/content/drive/MyDrive/AOD-Net/snapshot-\"+datetime.strftime(now,'%Y-%m-%d_%H:%M:%S')\n",
        "!mkdir $snapshotPaht"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZC6CO2eeF0es",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15272b27-1e91-483b-bcf6-a77c675289f9"
      },
      "source": [
        "!python -c \"import torch; print(torch.__version__)\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.7.0+cu101\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P5vAqPepIrIi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "136b5fb7-71f2-471e-9643-5d5b3a027513"
      },
      "source": [
        "!python -c \"import torchvision; print(torchvision.__version__)\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8.1+cu101\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gunmjw5QLaPS"
      },
      "source": [
        "!pip install torchvision==0.5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fJ53TKWKeTC"
      },
      "source": [
        "!pip install torch==1.4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TDgDNUJ0GfJ0",
        "outputId": "f3559c6f-5175-4997-d9a1-bf0f35701e70",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "! python train.py \\\n",
        "  --use_gpu 1 \\\n",
        "  --orig_images_path data/image/ \\\n",
        "  --snapshots_folder $snapshotPaht"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "snapshots_folder:/content/drive/MyDrive/AOD-Net/snapshot-2020-12-21_10:39:27\n",
            "sample_output_folder:samples/\n",
            "Total training examples: 63\n",
            "Total validation examples: 7\n",
            "Loss at index_ 20 / 720 :iteration_ 1 : 0.5982564687728882\n",
            "Loss at index_ 40 / 720 :iteration_ 1 : 0.6666666865348816\n",
            "Loss at index_ 60 / 720 :iteration_ 1 : nan\n",
            "Loss at index_ 80 / 720 :iteration_ 1 : 0.6680744886398315\n",
            "Loss at index_ 100 / 720 :iteration_ 1 : 0.6671921610832214\n",
            "Loss at index_ 120 / 720 :iteration_ 1 : nan\n",
            "Loss at index_ 140 / 720 :iteration_ 1 : 0.7386478781700134\n",
            "Loss at index_ 160 / 720 :iteration_ 1 : 0.6691813468933105\n",
            "Loss at index_ 180 / 720 :iteration_ 1 : nan\n",
            "Loss at index_ 200 / 720 :iteration_ 1 : 0.7645220756530762\n",
            "Loss at index_ 220 / 720 :iteration_ 1 : 0.6712597608566284\n",
            "Loss at index_ 240 / 720 :iteration_ 1 : nan\n",
            "Loss at index_ 260 / 720 :iteration_ 1 : 0.7434320449829102\n",
            "Loss at index_ 280 / 720 :iteration_ 1 : 0.6671711802482605\n",
            "Loss at index_ 300 / 720 :iteration_ 1 : nan\n",
            "Loss at index_ 320 / 720 :iteration_ 1 : 0.7362947463989258\n",
            "Loss at index_ 340 / 720 :iteration_ 1 : 0.6707520484924316\n",
            "Loss at index_ 360 / 720 :iteration_ 1 : nan\n",
            "Loss at index_ 380 / 720 :iteration_ 1 : 0.7434320449829102\n",
            "Loss at index_ 400 / 720 :iteration_ 1 : 0.6680905222892761\n",
            "Loss at index_ 420 / 720 :iteration_ 1 : nan\n",
            "Loss at index_ 440 / 720 :iteration_ 1 : 0.7375016212463379\n",
            "Loss at index_ 460 / 720 :iteration_ 1 : 0.6720941066741943\n",
            "Loss at index_ 480 / 720 :iteration_ 1 : nan\n",
            "Loss at index_ 500 / 720 :iteration_ 1 : 0.7340314388275146\n",
            "Loss at index_ 520 / 720 :iteration_ 1 : 0.6700567007064819\n",
            "Loss at index_ 540 / 720 :iteration_ 1 : nan\n",
            "Loss at index_ 560 / 720 :iteration_ 1 : 0.7434320449829102\n",
            "Loss at index_ 580 / 720 :iteration_ 1 : 0.6695179343223572\n",
            "Loss at index_ 600 / 720 :iteration_ 1 : nan\n",
            "Loss at index_ 620 / 720 :iteration_ 1 : 0.744959831237793\n",
            "Loss at index_ 640 / 720 :iteration_ 1 : 0.6667694449424744\n",
            "Loss at index_ 660 / 720 :iteration_ 1 : nan\n",
            "Loss at index_ 680 / 720 :iteration_ 1 : 0.6676607131958008\n",
            "Loss at index_ 700 / 720 :iteration_ 1 : nan\n",
            "Loss at index_ 720 / 720 :iteration_ 1 : nan\n",
            "Loss at index_ 20 / 240 :iteration_ 2 : 0.6666666865348816\n",
            "Loss at index_ 40 / 240 :iteration_ 2 : 0.6666666865348816\n",
            "Loss at index_ 60 / 240 :iteration_ 2 : 0.6666666865348816\n",
            "Loss at index_ 80 / 240 :iteration_ 2 : 0.6666666865348816\n",
            "Loss at index_ 100 / 240 :iteration_ 2 : 0.6666666865348816\n",
            "Loss at index_ 120 / 240 :iteration_ 2 : 0.6666666865348816\n",
            "Loss at index_ 140 / 240 :iteration_ 2 : 0.6666666865348816\n",
            "Loss at index_ 160 / 240 :iteration_ 2 : 0.6666666865348816\n",
            "Loss at index_ 180 / 240 :iteration_ 2 : 0.6666666865348816\n",
            "Loss at index_ 200 / 240 :iteration_ 2 : 0.6666666865348816\n",
            "Loss at index_ 220 / 240 :iteration_ 2 : 0.666749894618988\n",
            "Loss at index_ 240 / 240 :iteration_ 2 : nan\n",
            "Loss at index_ 20 / 160 :iteration_ 3 : 0.6666666865348816\n",
            "Loss at index_ 40 / 160 :iteration_ 3 : 0.6666666865348816\n",
            "Loss at index_ 60 / 160 :iteration_ 3 : 0.6666666865348816\n",
            "Loss at index_ 80 / 160 :iteration_ 3 : 0.6666666865348816\n",
            "Loss at index_ 100 / 160 :iteration_ 3 : 0.6666666865348816\n",
            "Loss at index_ 120 / 160 :iteration_ 3 : 0.6666666865348816\n",
            "Loss at index_ 140 / 160 :iteration_ 3 : 0.6666666865348816\n",
            "Loss at index_ 160 / 160 :iteration_ 3 : nan\n",
            "Loss at index_ 20 / 220 :iteration_ 4 : nan\n",
            "Loss at index_ 40 / 220 :iteration_ 4 : nan\n",
            "Loss at index_ 60 / 220 :iteration_ 4 : nan\n",
            "Loss at index_ 80 / 220 :iteration_ 4 : nan\n",
            "Loss at index_ 100 / 220 :iteration_ 4 : nan\n",
            "Loss at index_ 120 / 220 :iteration_ 4 : nan\n",
            "Loss at index_ 140 / 220 :iteration_ 4 : nan\n",
            "Loss at index_ 160 / 220 :iteration_ 4 : nan\n",
            "Loss at index_ 180 / 220 :iteration_ 4 : nan\n",
            "Loss at index_ 200 / 220 :iteration_ 4 : nan\n",
            "Loss at index_ 220 / 220 :iteration_ 4 : nan\n",
            "Loss at index_ 20 / 768 :iteration_ 5 : 0.6666666865348816\n",
            "Loss at index_ 40 / 768 :iteration_ 5 : 0.6666666865348816\n",
            "Loss at index_ 60 / 768 :iteration_ 5 : 0.6630638837814331\n",
            "Loss at index_ 80 / 768 :iteration_ 5 : 0.6666666865348816\n",
            "Loss at index_ 100 / 768 :iteration_ 5 : 0.6666666865348816\n",
            "Loss at index_ 120 / 768 :iteration_ 5 : 0.6666666865348816\n",
            "Loss at index_ 140 / 768 :iteration_ 5 : 0.6315214037895203\n",
            "Loss at index_ 160 / 768 :iteration_ 5 : 0.6666666865348816\n",
            "Loss at index_ 180 / 768 :iteration_ 5 : 0.6515277624130249\n",
            "Loss at index_ 200 / 768 :iteration_ 5 : 0.6429429054260254\n",
            "Loss at index_ 220 / 768 :iteration_ 5 : 0.6328442096710205\n",
            "Loss at index_ 240 / 768 :iteration_ 5 : 0.6466109156608582\n",
            "Loss at index_ 260 / 768 :iteration_ 5 : 0.6666666865348816\n",
            "Loss at index_ 280 / 768 :iteration_ 5 : 0.6469173431396484\n",
            "Loss at index_ 300 / 768 :iteration_ 5 : 0.6574143767356873\n",
            "Loss at index_ 320 / 768 :iteration_ 5 : 0.6666666865348816\n",
            "Loss at index_ 340 / 768 :iteration_ 5 : 0.6437658071517944\n",
            "Loss at index_ 360 / 768 :iteration_ 5 : 0.6508299112319946\n",
            "Loss at index_ 380 / 768 :iteration_ 5 : 0.6666666865348816\n",
            "Loss at index_ 400 / 768 :iteration_ 5 : 0.6666666865348816\n",
            "Loss at index_ 420 / 768 :iteration_ 5 : 0.6111592054367065\n",
            "Loss at index_ 440 / 768 :iteration_ 5 : 0.6666666865348816\n",
            "Loss at index_ 460 / 768 :iteration_ 5 : 0.6580924391746521\n",
            "Loss at index_ 480 / 768 :iteration_ 5 : 0.6666666865348816\n",
            "Loss at index_ 500 / 768 :iteration_ 5 : 0.6649532318115234\n",
            "Loss at index_ 520 / 768 :iteration_ 5 : 0.6496675610542297\n",
            "Loss at index_ 540 / 768 :iteration_ 5 : 0.6666666865348816\n",
            "Loss at index_ 560 / 768 :iteration_ 5 : 0.6407588720321655\n",
            "Loss at index_ 580 / 768 :iteration_ 5 : 0.6662602424621582\n",
            "Loss at index_ 600 / 768 :iteration_ 5 : 0.6468490362167358\n",
            "Loss at index_ 620 / 768 :iteration_ 5 : 0.6534491181373596\n",
            "Loss at index_ 640 / 768 :iteration_ 5 : 0.6666666865348816\n",
            "Loss at index_ 660 / 768 :iteration_ 5 : 0.6666666865348816\n",
            "Loss at index_ 680 / 768 :iteration_ 5 : 0.6666666865348816\n",
            "Loss at index_ 700 / 768 :iteration_ 5 : 0.6680700182914734\n",
            "Loss at index_ 720 / 768 :iteration_ 5 : 0.6666666865348816\n",
            "Loss at index_ 740 / 768 :iteration_ 5 : 0.6666666865348816\n",
            "Loss at index_ 760 / 768 :iteration_ 5 : 0.6666666865348816\n",
            "Loss at index_ 20 / 140 :iteration_ 6 : 0.6666666865348816\n",
            "Loss at index_ 40 / 140 :iteration_ 6 : 0.6666666865348816\n",
            "Loss at index_ 60 / 140 :iteration_ 6 : 0.6675883531570435\n",
            "Loss at index_ 80 / 140 :iteration_ 6 : 0.6753309965133667\n",
            "Loss at index_ 100 / 140 :iteration_ 6 : 0.6666666865348816\n",
            "Loss at index_ 120 / 140 :iteration_ 6 : 0.6945403814315796\n",
            "Loss at index_ 140 / 140 :iteration_ 6 : nan\n",
            "Loss at index_ 20 / 768 :iteration_ 7 : 0.6666666865348816\n",
            "Loss at index_ 40 / 768 :iteration_ 7 : 0.6666666865348816\n",
            "Loss at index_ 60 / 768 :iteration_ 7 : 0.6586824655532837\n",
            "Loss at index_ 80 / 768 :iteration_ 7 : 0.6666666865348816\n",
            "Loss at index_ 100 / 768 :iteration_ 7 : 0.6666666865348816\n",
            "Loss at index_ 120 / 768 :iteration_ 7 : 0.6666666865348816\n",
            "Loss at index_ 140 / 768 :iteration_ 7 : 0.6863255500793457\n",
            "Loss at index_ 160 / 768 :iteration_ 7 : 0.6666666865348816\n",
            "Loss at index_ 180 / 768 :iteration_ 7 : 0.7282788753509521\n",
            "Loss at index_ 200 / 768 :iteration_ 7 : 0.6666666865348816\n",
            "Loss at index_ 220 / 768 :iteration_ 7 : 0.6666666865348816\n",
            "Loss at index_ 240 / 768 :iteration_ 7 : 0.7015645503997803\n",
            "Loss at index_ 260 / 768 :iteration_ 7 : 0.6666666865348816\n",
            "Loss at index_ 280 / 768 :iteration_ 7 : 0.7282788753509521\n",
            "Loss at index_ 300 / 768 :iteration_ 7 : 0.7123443484306335\n",
            "Loss at index_ 320 / 768 :iteration_ 7 : 0.6666666865348816\n",
            "Loss at index_ 340 / 768 :iteration_ 7 : 0.7496212720870972\n",
            "Loss at index_ 360 / 768 :iteration_ 7 : 0.6666666865348816\n",
            "Loss at index_ 380 / 768 :iteration_ 7 : 0.6666666865348816\n",
            "Loss at index_ 400 / 768 :iteration_ 7 : 0.6775660514831543\n",
            "Loss at index_ 420 / 768 :iteration_ 7 : 0.6666666865348816\n",
            "Loss at index_ 440 / 768 :iteration_ 7 : 0.6779087781906128\n",
            "Loss at index_ 460 / 768 :iteration_ 7 : 0.6712934374809265\n",
            "Loss at index_ 480 / 768 :iteration_ 7 : 0.6666666865348816\n",
            "Loss at index_ 500 / 768 :iteration_ 7 : 0.6773443222045898\n",
            "Loss at index_ 520 / 768 :iteration_ 7 : 0.6666666865348816\n",
            "Loss at index_ 540 / 768 :iteration_ 7 : 0.6666666865348816\n",
            "Loss at index_ 560 / 768 :iteration_ 7 : 0.6779431104660034\n",
            "Loss at index_ 580 / 768 :iteration_ 7 : 0.6666666865348816\n",
            "Loss at index_ 600 / 768 :iteration_ 7 : 0.671351432800293\n",
            "Loss at index_ 620 / 768 :iteration_ 7 : 0.6788341403007507\n",
            "Loss at index_ 640 / 768 :iteration_ 7 : 0.6666666865348816\n",
            "Loss at index_ 660 / 768 :iteration_ 7 : 0.6998428702354431\n",
            "Loss at index_ 680 / 768 :iteration_ 7 : 0.6666666865348816\n",
            "Loss at index_ 700 / 768 :iteration_ 7 : 0.6680700182914734\n",
            "Loss at index_ 720 / 768 :iteration_ 7 : 0.6666666865348816\n",
            "Loss at index_ 740 / 768 :iteration_ 7 : 0.6666666865348816\n",
            "/content/drive/MyDrive/AOD-Net/snapshot-2020-12-21_10:39:27\n",
            "/content/drive/MyDrive/AOD-Net/snapshot-2020-12-21_10:39:27Epoch:\n",
            "/content/drive/MyDrive/AOD-Net/snapshot-2020-12-21_10:39:27Epoch:0\n",
            "/content/drive/MyDrive/AOD-Net/snapshot-2020-12-21_10:39:27Epoch:0_TrainTimes:\n",
            "/content/drive/MyDrive/AOD-Net/snapshot-2020-12-21_10:39:27Epoch:0_TrainTimes:3000\n",
            "/content/drive/MyDrive/AOD-Net/snapshot-2020-12-21_10:39:27Epoch:0_TrainTimes:3000.pth\n",
            "Loss at index_ 760 / 768 :iteration_ 7 : 0.6666666865348816\n",
            "Loss at index_ 20 / 300 :iteration_ 8 : 0.7536090612411499\n",
            "Loss at index_ 40 / 300 :iteration_ 8 : 0.6666666865348816\n",
            "Loss at index_ 60 / 300 :iteration_ 8 : 0.6752958297729492\n",
            "Loss at index_ 80 / 300 :iteration_ 8 : 0.6724991798400879\n",
            "Loss at index_ 100 / 300 :iteration_ 8 : 0.6745559573173523\n",
            "Loss at index_ 120 / 300 :iteration_ 8 : 0.6745559573173523\n",
            "Loss at index_ 140 / 300 :iteration_ 8 : 0.6745559573173523\n",
            "Loss at index_ 160 / 300 :iteration_ 8 : 0.6745559573173523\n",
            "Loss at index_ 180 / 300 :iteration_ 8 : 0.6745559573173523\n",
            "Loss at index_ 200 / 300 :iteration_ 8 : 0.6745559573173523\n",
            "Loss at index_ 220 / 300 :iteration_ 8 : 0.6745559573173523\n",
            "Loss at index_ 240 / 300 :iteration_ 8 : 0.6745559573173523\n",
            "Loss at index_ 260 / 300 :iteration_ 8 : 0.6745559573173523\n",
            "Loss at index_ 280 / 300 :iteration_ 8 : 0.6679867506027222\n",
            "Loss at index_ 300 / 300 :iteration_ 8 : nan\n",
            "Loss at index_ 20 / 154 :iteration_ 9 : 0.6692379713058472\n",
            "Loss at index_ 40 / 154 :iteration_ 9 : 0.6666666865348816\n",
            "Loss at index_ 60 / 154 :iteration_ 9 : 0.6666802763938904\n",
            "Loss at index_ 80 / 154 :iteration_ 9 : 0.6666666865348816\n",
            "Loss at index_ 100 / 154 :iteration_ 9 : 0.6679961085319519\n",
            "Loss at index_ 120 / 154 :iteration_ 9 : 0.6736637949943542\n",
            "Loss at index_ 140 / 154 :iteration_ 9 : nan\n",
            "Loss at index_ 20 / 768 :iteration_ 10 : 0.6661869287490845\n",
            "Loss at index_ 40 / 768 :iteration_ 10 : 0.6666666865348816\n",
            "Loss at index_ 60 / 768 :iteration_ 10 : 0.6615243554115295\n",
            "Loss at index_ 80 / 768 :iteration_ 10 : 0.6666666865348816\n",
            "Loss at index_ 100 / 768 :iteration_ 10 : 0.6666666865348816\n",
            "Loss at index_ 120 / 768 :iteration_ 10 : 0.6666666865348816\n",
            "Loss at index_ 140 / 768 :iteration_ 10 : 0.6144620776176453\n",
            "Loss at index_ 160 / 768 :iteration_ 10 : 0.6666666865348816\n",
            "Loss at index_ 180 / 768 :iteration_ 10 : 0.6666666865348816\n",
            "Loss at index_ 200 / 768 :iteration_ 10 : 0.6768155097961426\n",
            "Loss at index_ 220 / 768 :iteration_ 10 : 0.6666666865348816\n",
            "Loss at index_ 240 / 768 :iteration_ 10 : 0.6666666865348816\n",
            "Loss at index_ 260 / 768 :iteration_ 10 : 0.6666666865348816\n",
            "Loss at index_ 280 / 768 :iteration_ 10 : 0.6666666865348816\n",
            "Loss at index_ 300 / 768 :iteration_ 10 : 0.6465154886245728\n",
            "Loss at index_ 320 / 768 :iteration_ 10 : 0.6666666865348816\n",
            "Loss at index_ 340 / 768 :iteration_ 10 : 0.6666666865348816\n",
            "Loss at index_ 360 / 768 :iteration_ 10 : 0.6666666865348816\n",
            "Loss at index_ 380 / 768 :iteration_ 10 : 0.6666666865348816\n",
            "Loss at index_ 400 / 768 :iteration_ 10 : 0.72645103931427\n",
            "Loss at index_ 420 / 768 :iteration_ 10 : 0.6666666865348816\n",
            "Loss at index_ 440 / 768 :iteration_ 10 : 0.6666666865348816\n",
            "Loss at index_ 460 / 768 :iteration_ 10 : 0.6417092680931091\n",
            "Loss at index_ 480 / 768 :iteration_ 10 : 0.6666666865348816\n",
            "Loss at index_ 500 / 768 :iteration_ 10 : 0.6666666865348816\n",
            "Loss at index_ 520 / 768 :iteration_ 10 : 0.6666666865348816\n",
            "Loss at index_ 540 / 768 :iteration_ 10 : 0.6666666865348816\n",
            "Loss at index_ 560 / 768 :iteration_ 10 : 0.7325562238693237\n",
            "Loss at index_ 580 / 768 :iteration_ 10 : 0.6666666865348816\n",
            "Loss at index_ 600 / 768 :iteration_ 10 : 0.6666666865348816\n",
            "Loss at index_ 620 / 768 :iteration_ 10 : 0.6438422203063965\n",
            "Loss at index_ 640 / 768 :iteration_ 10 : 0.6666666865348816\n",
            "Loss at index_ 660 / 768 :iteration_ 10 : 0.6666666865348816\n",
            "Loss at index_ 680 / 768 :iteration_ 10 : 0.6666666865348816\n",
            "Loss at index_ 700 / 768 :iteration_ 10 : 0.6680700182914734\n",
            "Loss at index_ 720 / 768 :iteration_ 10 : 0.5979936122894287\n",
            "Loss at index_ 740 / 768 :iteration_ 10 : 0.6666666865348816\n",
            "Loss at index_ 760 / 768 :iteration_ 10 : 0.6666666865348816\n",
            "Loss at iteration 10 : 0.6666666865348816\n",
            "Loss at index_ 20 / 288 :iteration_ 11 : 0.6704192161560059\n",
            "Loss at index_ 40 / 288 :iteration_ 11 : 0.6835651397705078\n",
            "Loss at index_ 60 / 288 :iteration_ 11 : 0.6732560992240906\n",
            "Loss at index_ 80 / 288 :iteration_ 11 : 0.6641072630882263\n",
            "Loss at index_ 100 / 288 :iteration_ 11 : 0.6623541116714478\n",
            "Loss at index_ 120 / 288 :iteration_ 11 : nan\n",
            "Loss at index_ 140 / 288 :iteration_ 11 : 0.6643650531768799\n",
            "Loss at index_ 160 / 288 :iteration_ 11 : 0.6651142835617065\n",
            "Loss at index_ 180 / 288 :iteration_ 11 : 0.6643924117088318\n",
            "Loss at index_ 200 / 288 :iteration_ 11 : 0.6620434522628784\n",
            "Loss at index_ 220 / 288 :iteration_ 11 : 0.6666666865348816\n",
            "Loss at index_ 240 / 288 :iteration_ 11 : nan\n",
            "Loss at index_ 260 / 288 :iteration_ 11 : 0.6666666865348816\n",
            "Loss at index_ 280 / 288 :iteration_ 11 : nan\n",
            "Loss at index_ 20 / 200 :iteration_ 12 : 0.6666666865348816\n",
            "Loss at index_ 40 / 200 :iteration_ 12 : 0.6666666865348816\n",
            "Loss at index_ 60 / 200 :iteration_ 12 : 0.6666666865348816\n",
            "Loss at index_ 80 / 200 :iteration_ 12 : 0.6666666865348816\n",
            "Loss at index_ 100 / 200 :iteration_ 12 : 0.6666666865348816\n",
            "Loss at index_ 120 / 200 :iteration_ 12 : 0.6666666865348816\n",
            "Loss at index_ 140 / 200 :iteration_ 12 : 0.6626083850860596\n",
            "Loss at index_ 160 / 200 :iteration_ 12 : 0.6640884280204773\n",
            "Loss at index_ 180 / 200 :iteration_ 12 : 0.6666666865348816\n",
            "Loss at index_ 200 / 200 :iteration_ 12 : nan\n",
            "Loss at index_ 20 / 260 :iteration_ 13 : 0.6685103178024292\n",
            "Loss at index_ 40 / 260 :iteration_ 13 : 0.6674239039421082\n",
            "Loss at index_ 60 / 260 :iteration_ 13 : 0.6669011116027832\n",
            "Loss at index_ 80 / 260 :iteration_ 13 : 0.6666337847709656\n",
            "Loss at index_ 100 / 260 :iteration_ 13 : 0.6892597079277039\n",
            "Loss at index_ 120 / 260 :iteration_ 13 : 0.6675666570663452\n",
            "Loss at index_ 140 / 260 :iteration_ 13 : 0.6666097640991211\n",
            "Loss at index_ 160 / 260 :iteration_ 13 : 0.6675639152526855\n",
            "Loss at index_ 180 / 260 :iteration_ 13 : 0.6666174530982971\n",
            "Loss at index_ 200 / 260 :iteration_ 13 : 0.6673337817192078\n",
            "Loss at index_ 220 / 260 :iteration_ 13 : 0.6673191785812378\n",
            "Loss at index_ 240 / 260 :iteration_ 13 : 0.6675379276275635\n",
            "Loss at index_ 260 / 260 :iteration_ 13 : nan\n",
            "Loss at index_ 20 / 260 :iteration_ 14 : 0.6666666865348816\n",
            "Loss at index_ 40 / 260 :iteration_ 14 : 0.6666666865348816\n",
            "Loss at index_ 60 / 260 :iteration_ 14 : 0.6666666865348816\n",
            "Loss at index_ 80 / 260 :iteration_ 14 : 0.6666666865348816\n",
            "Loss at index_ 100 / 260 :iteration_ 14 : 0.6666666865348816\n",
            "Loss at index_ 120 / 260 :iteration_ 14 : 0.6666666865348816\n",
            "Loss at index_ 140 / 260 :iteration_ 14 : 0.6666666865348816\n",
            "Loss at index_ 160 / 260 :iteration_ 14 : 0.6666666865348816\n",
            "Loss at index_ 180 / 260 :iteration_ 14 : 0.6666666865348816\n",
            "Loss at index_ 200 / 260 :iteration_ 14 : 0.6666666865348816\n",
            "Loss at index_ 220 / 260 :iteration_ 14 : 0.6666666865348816\n",
            "Loss at index_ 240 / 260 :iteration_ 14 : 0.6667248606681824\n",
            "Loss at index_ 260 / 260 :iteration_ 14 : nan\n",
            "Loss at index_ 20 / 768 :iteration_ 15 : 0.6666666865348816\n",
            "Loss at index_ 40 / 768 :iteration_ 15 : 0.6666666865348816\n",
            "Loss at index_ 60 / 768 :iteration_ 15 : 0.6666666865348816\n",
            "Loss at index_ 80 / 768 :iteration_ 15 : 0.6666666865348816\n",
            "Loss at index_ 100 / 768 :iteration_ 15 : 0.6666666865348816\n",
            "Loss at index_ 120 / 768 :iteration_ 15 : 0.6666666865348816\n",
            "Loss at index_ 140 / 768 :iteration_ 15 : 0.6285908222198486\n",
            "Loss at index_ 160 / 768 :iteration_ 15 : 0.6666666865348816\n",
            "Loss at index_ 180 / 768 :iteration_ 15 : 0.6100265979766846\n",
            "Loss at index_ 200 / 768 :iteration_ 15 : 0.6074827909469604\n",
            "Loss at index_ 220 / 768 :iteration_ 15 : 0.6643446683883667\n",
            "Loss at index_ 240 / 768 :iteration_ 15 : 0.6322140693664551\n",
            "Loss at index_ 260 / 768 :iteration_ 15 : 0.6864948272705078\n",
            "Loss at index_ 280 / 768 :iteration_ 15 : 0.670142412185669\n",
            "Loss at index_ 300 / 768 :iteration_ 15 : 0.6666666865348816\n",
            "Loss at index_ 320 / 768 :iteration_ 15 : 0.6666666865348816\n",
            "Loss at index_ 340 / 768 :iteration_ 15 : 0.6666666865348816\n",
            "Loss at index_ 360 / 768 :iteration_ 15 : 0.6835998892784119\n",
            "Loss at index_ 380 / 768 :iteration_ 15 : 0.6641545295715332\n",
            "Loss at index_ 400 / 768 :iteration_ 15 : 0.6666666865348816\n",
            "Loss at index_ 420 / 768 :iteration_ 15 : 0.6666666865348816\n",
            "Loss at index_ 440 / 768 :iteration_ 15 : 0.6666666865348816\n",
            "Loss at index_ 460 / 768 :iteration_ 15 : 0.7326475977897644\n",
            "Loss at index_ 480 / 768 :iteration_ 15 : 0.6666666865348816\n",
            "Loss at index_ 500 / 768 :iteration_ 15 : 0.6666666865348816\n",
            "Loss at index_ 520 / 768 :iteration_ 15 : 0.6831411123275757\n",
            "Loss at index_ 540 / 768 :iteration_ 15 : 0.6638785600662231\n",
            "Loss at index_ 560 / 768 :iteration_ 15 : 0.6666666865348816\n",
            "Loss at index_ 580 / 768 :iteration_ 15 : 0.6666666865348816\n",
            "Loss at index_ 600 / 768 :iteration_ 15 : 0.650060772895813\n",
            "Loss at index_ 620 / 768 :iteration_ 15 : 0.7319650650024414\n",
            "Loss at index_ 640 / 768 :iteration_ 15 : 0.6666666865348816\n",
            "Loss at index_ 660 / 768 :iteration_ 15 : 0.6648365259170532\n",
            "Loss at index_ 680 / 768 :iteration_ 15 : 0.6666666865348816\n",
            "Loss at index_ 700 / 768 :iteration_ 15 : 0.6680700182914734\n",
            "Loss at index_ 720 / 768 :iteration_ 15 : 0.6666666865348816\n",
            "Loss at index_ 740 / 768 :iteration_ 15 : 0.6666666865348816\n",
            "/content/drive/MyDrive/AOD-Net/snapshot-2020-12-21_10:39:27\n",
            "/content/drive/MyDrive/AOD-Net/snapshot-2020-12-21_10:39:27Epoch:\n",
            "/content/drive/MyDrive/AOD-Net/snapshot-2020-12-21_10:39:27Epoch:0\n",
            "/content/drive/MyDrive/AOD-Net/snapshot-2020-12-21_10:39:27Epoch:0_TrainTimes:\n",
            "/content/drive/MyDrive/AOD-Net/snapshot-2020-12-21_10:39:27Epoch:0_TrainTimes:6000\n",
            "/content/drive/MyDrive/AOD-Net/snapshot-2020-12-21_10:39:27Epoch:0_TrainTimes:6000.pth\n",
            "Loss at index_ 760 / 768 :iteration_ 15 : 0.6666666865348816\n",
            "Loss at index_ 20 / 840 :iteration_ 16 : 0.7632262110710144\n",
            "Loss at index_ 40 / 840 :iteration_ 16 : 0.7334260940551758\n",
            "Loss at index_ 60 / 840 :iteration_ 16 : 0.6856061816215515\n",
            "Loss at index_ 80 / 840 :iteration_ 16 : 0.609520435333252\n",
            "Loss at index_ 100 / 840 :iteration_ 16 : 0.8010993003845215\n",
            "Loss at index_ 120 / 840 :iteration_ 16 : 0.6690489649772644\n",
            "Loss at index_ 140 / 840 :iteration_ 16 : 0.7169088125228882\n",
            "Loss at index_ 160 / 840 :iteration_ 16 : 0.667593240737915\n",
            "Loss at index_ 180 / 840 :iteration_ 16 : 0.6842284202575684\n",
            "Loss at index_ 200 / 840 :iteration_ 16 : 0.7412232160568237\n",
            "Loss at index_ 220 / 840 :iteration_ 16 : 0.6931560039520264\n",
            "Loss at index_ 240 / 840 :iteration_ 16 : 0.6706576347351074\n",
            "Loss at index_ 260 / 840 :iteration_ 16 : 0.7043219804763794\n",
            "Loss at index_ 280 / 840 :iteration_ 16 : 0.7047799825668335\n",
            "Loss at index_ 300 / 840 :iteration_ 16 : 0.6728458404541016\n",
            "Loss at index_ 320 / 840 :iteration_ 16 : 0.6436306834220886\n",
            "Loss at index_ 340 / 840 :iteration_ 16 : 0.6710178256034851\n",
            "Loss at index_ 360 / 840 :iteration_ 16 : 0.6701036691665649\n",
            "Loss at index_ 380 / 840 :iteration_ 16 : 0.6715379953384399\n",
            "Loss at index_ 400 / 840 :iteration_ 16 : 0.6735053062438965\n",
            "Loss at index_ 420 / 840 :iteration_ 16 : nan\n",
            "Loss at index_ 440 / 840 :iteration_ 16 : 0.669333815574646\n",
            "Loss at index_ 460 / 840 :iteration_ 16 : 0.6719025373458862\n",
            "Loss at index_ 480 / 840 :iteration_ 16 : 0.6705045104026794\n",
            "Loss at index_ 500 / 840 :iteration_ 16 : 0.6713299751281738\n",
            "Loss at index_ 520 / 840 :iteration_ 16 : 0.6710710525512695\n",
            "Loss at index_ 540 / 840 :iteration_ 16 : 0.7229353785514832\n",
            "Loss at index_ 560 / 840 :iteration_ 16 : 0.673243522644043\n",
            "Loss at index_ 580 / 840 :iteration_ 16 : 0.7008668780326843\n",
            "Loss at index_ 600 / 840 :iteration_ 16 : 0.6702678203582764\n",
            "Loss at index_ 620 / 840 :iteration_ 16 : 0.6983182430267334\n",
            "Loss at index_ 640 / 840 :iteration_ 16 : 0.6820542216300964\n",
            "Loss at index_ 660 / 840 :iteration_ 16 : 0.6699529886245728\n",
            "Loss at index_ 680 / 840 :iteration_ 16 : 0.6700246334075928\n",
            "Loss at index_ 700 / 840 :iteration_ 16 : 0.673031210899353\n",
            "Loss at index_ 720 / 840 :iteration_ 16 : 0.6698035001754761\n",
            "Loss at index_ 740 / 840 :iteration_ 16 : 0.670753002166748\n",
            "Loss at index_ 760 / 840 :iteration_ 16 : 0.6720993518829346\n",
            "Loss at index_ 780 / 840 :iteration_ 16 : 0.6708289980888367\n",
            "Loss at index_ 800 / 840 :iteration_ 16 : nan\n",
            "Loss at index_ 820 / 840 :iteration_ 16 : nan\n",
            "Loss at index_ 840 / 840 :iteration_ 16 : nan\n",
            "Loss at index_ 20 / 144 :iteration_ 17 : 0.6627658009529114\n",
            "Loss at index_ 40 / 144 :iteration_ 17 : 0.6683864593505859\n",
            "Loss at index_ 60 / 144 :iteration_ 17 : 0.6666666865348816\n",
            "Loss at index_ 80 / 144 :iteration_ 17 : 0.6666666865348816\n",
            "Loss at index_ 100 / 144 :iteration_ 17 : 0.6673333048820496\n",
            "Loss at index_ 120 / 144 :iteration_ 17 : 0.666164755821228\n",
            "Loss at index_ 140 / 144 :iteration_ 17 : nan\n",
            "Loss at index_ 20 / 140 :iteration_ 18 : 0.6666666865348816\n",
            "Loss at index_ 40 / 140 :iteration_ 18 : 0.6666666865348816\n",
            "Loss at index_ 60 / 140 :iteration_ 18 : 0.6666666865348816\n",
            "Loss at index_ 80 / 140 :iteration_ 18 : 0.6756963729858398\n",
            "Loss at index_ 100 / 140 :iteration_ 18 : 0.6666666865348816\n",
            "Loss at index_ 120 / 140 :iteration_ 18 : 0.6761621236801147\n",
            "Loss at index_ 140 / 140 :iteration_ 18 : nan\n",
            "Loss at index_ 20 / 768 :iteration_ 19 : 0.6666666865348816\n",
            "Loss at index_ 40 / 768 :iteration_ 19 : 0.6666666865348816\n",
            "Loss at index_ 60 / 768 :iteration_ 19 : 0.6615148782730103\n",
            "Loss at index_ 80 / 768 :iteration_ 19 : 0.6666666865348816\n",
            "Loss at index_ 100 / 768 :iteration_ 19 : 0.6666666865348816\n",
            "Loss at index_ 120 / 768 :iteration_ 19 : 0.6666666865348816\n",
            "Loss at index_ 140 / 768 :iteration_ 19 : 0.634041428565979\n",
            "Loss at index_ 160 / 768 :iteration_ 19 : 0.6666666865348816\n",
            "Loss at index_ 180 / 768 :iteration_ 19 : 0.6615630388259888\n",
            "Loss at index_ 200 / 768 :iteration_ 19 : 0.646541953086853\n",
            "Loss at index_ 220 / 768 :iteration_ 19 : 0.6549458503723145\n",
            "Loss at index_ 240 / 768 :iteration_ 19 : 0.6666666865348816\n",
            "Loss at index_ 260 / 768 :iteration_ 19 : 0.6621329188346863\n",
            "Loss at index_ 280 / 768 :iteration_ 19 : 0.6666666865348816\n",
            "Loss at index_ 300 / 768 :iteration_ 19 : 0.6531632542610168\n",
            "Loss at index_ 320 / 768 :iteration_ 19 : 0.6666666865348816\n",
            "Loss at index_ 340 / 768 :iteration_ 19 : 0.6666666865348816\n",
            "Loss at index_ 360 / 768 :iteration_ 19 : 0.6545379757881165\n",
            "Loss at index_ 380 / 768 :iteration_ 19 : 0.6666666865348816\n",
            "Loss at index_ 400 / 768 :iteration_ 19 : 0.6600605845451355\n",
            "Loss at index_ 420 / 768 :iteration_ 19 : 0.6270541548728943\n",
            "Loss at index_ 440 / 768 :iteration_ 19 : 0.6193612217903137\n",
            "Loss at index_ 460 / 768 :iteration_ 19 : 0.6561633944511414\n",
            "Loss at index_ 480 / 768 :iteration_ 19 : 0.6666666865348816\n",
            "Loss at index_ 500 / 768 :iteration_ 19 : 0.6586759090423584\n",
            "Loss at index_ 520 / 768 :iteration_ 19 : 0.6484020948410034\n",
            "Loss at index_ 540 / 768 :iteration_ 19 : 0.6666666865348816\n",
            "Loss at index_ 560 / 768 :iteration_ 19 : 0.6373317241668701\n",
            "Loss at index_ 580 / 768 :iteration_ 19 : 0.6481530070304871\n",
            "Loss at index_ 600 / 768 :iteration_ 19 : 0.6666666865348816\n",
            "Loss at index_ 620 / 768 :iteration_ 19 : 0.6433019638061523\n",
            "Loss at index_ 640 / 768 :iteration_ 19 : 0.6666666865348816\n",
            "Loss at index_ 660 / 768 :iteration_ 19 : 0.6666666865348816\n",
            "Loss at index_ 680 / 768 :iteration_ 19 : 0.6666666865348816\n",
            "Loss at index_ 700 / 768 :iteration_ 19 : 0.6680700182914734\n",
            "Loss at index_ 720 / 768 :iteration_ 19 : 0.6666666865348816\n",
            "Loss at index_ 740 / 768 :iteration_ 19 : 0.6666666865348816\n",
            "Loss at index_ 760 / 768 :iteration_ 19 : 0.6666666865348816\n",
            "Loss at index_ 20 / 190 :iteration_ 20 : 0.6667076945304871\n",
            "Loss at index_ 40 / 190 :iteration_ 20 : 0.6717685461044312\n",
            "Loss at index_ 60 / 190 :iteration_ 20 : 0.8338724374771118\n",
            "Loss at index_ 80 / 190 :iteration_ 20 : 0.704285740852356\n",
            "Loss at index_ 100 / 190 :iteration_ 20 : 0.6666666865348816\n",
            "Loss at index_ 120 / 190 :iteration_ 20 : 0.6666666865348816\n",
            "Loss at index_ 140 / 190 :iteration_ 20 : 0.6666666865348816\n",
            "Loss at index_ 160 / 190 :iteration_ 20 : 0.6666666865348816\n",
            "Loss at index_ 180 / 190 :iteration_ 20 : nan\n",
            "Loss at iteration 20 : nan\n",
            "Loss at index_ 20 / 722 :iteration_ 21 : 0.661040186882019\n",
            "Loss at index_ 40 / 722 :iteration_ 21 : 0.6585761904716492\n",
            "Loss at index_ 60 / 722 :iteration_ 21 : 0.6619256734848022\n",
            "Loss at index_ 80 / 722 :iteration_ 21 : 0.6666666865348816\n",
            "Loss at index_ 100 / 722 :iteration_ 21 : 0.6666666865348816\n",
            "Loss at index_ 120 / 722 :iteration_ 21 : 0.6671457290649414\n",
            "Loss at index_ 140 / 722 :iteration_ 21 : 0.671139121055603\n",
            "Loss at index_ 160 / 722 :iteration_ 21 : 0.6754055023193359\n",
            "Loss at index_ 180 / 722 :iteration_ 21 : 0.764796257019043\n",
            "Loss at index_ 200 / 722 :iteration_ 21 : 0.6666666865348816\n",
            "Loss at index_ 220 / 722 :iteration_ 21 : 0.6696292757987976\n",
            "Loss at index_ 240 / 722 :iteration_ 21 : 0.6666666865348816\n",
            "Loss at index_ 260 / 722 :iteration_ 21 : 0.6666666865348816\n",
            "Loss at index_ 280 / 722 :iteration_ 21 : 0.6623176336288452\n",
            "Loss at index_ 300 / 722 :iteration_ 21 : 0.6622039079666138\n",
            "Loss at index_ 320 / 722 :iteration_ 21 : 0.6666666865348816\n",
            "Loss at index_ 340 / 722 :iteration_ 21 : 0.6666666865348816\n",
            "Loss at index_ 360 / 722 :iteration_ 21 : 0.6666666865348816\n",
            "Loss at index_ 380 / 722 :iteration_ 21 : nan\n",
            "Loss at index_ 400 / 722 :iteration_ 21 : 0.6666666865348816\n",
            "Loss at index_ 420 / 722 :iteration_ 21 : 0.6666666865348816\n",
            "Loss at index_ 440 / 722 :iteration_ 21 : 0.6666666865348816\n",
            "Loss at index_ 460 / 722 :iteration_ 21 : 0.6666666865348816\n",
            "Loss at index_ 480 / 722 :iteration_ 21 : 0.6666666865348816\n",
            "Loss at index_ 500 / 722 :iteration_ 21 : 0.6666666865348816\n",
            "Loss at index_ 520 / 722 :iteration_ 21 : 0.6666666865348816\n",
            "Loss at index_ 540 / 722 :iteration_ 21 : 0.6666666865348816\n",
            "Loss at index_ 560 / 722 :iteration_ 21 : 0.6666666865348816\n",
            "Loss at index_ 580 / 722 :iteration_ 21 : 0.6666666865348816\n",
            "Loss at index_ 600 / 722 :iteration_ 21 : 0.6666666865348816\n",
            "Loss at index_ 620 / 722 :iteration_ 21 : 0.6666666865348816\n",
            "Loss at index_ 640 / 722 :iteration_ 21 : 0.6666666865348816\n",
            "Loss at index_ 660 / 722 :iteration_ 21 : 0.6666666865348816\n",
            "Loss at index_ 680 / 722 :iteration_ 21 : 0.6666666865348816\n",
            "Loss at index_ 700 / 722 :iteration_ 21 : nan\n",
            "Loss at index_ 720 / 722 :iteration_ 21 : nan\n",
            "Loss at index_ 20 / 114 :iteration_ 22 : 0.6706746816635132\n",
            "Loss at index_ 40 / 114 :iteration_ 22 : 0.661872386932373\n",
            "Loss at index_ 60 / 114 :iteration_ 22 : 0.6598491072654724\n",
            "Loss at index_ 80 / 114 :iteration_ 22 : 0.6630226969718933\n",
            "Loss at index_ 100 / 114 :iteration_ 22 : nan\n",
            "Loss at index_ 20 / 216 :iteration_ 23 : 0.6685773730278015\n",
            "Loss at index_ 40 / 216 :iteration_ 23 : 0.6686624884605408\n",
            "Loss at index_ 60 / 216 :iteration_ 23 : 0.6725437045097351\n",
            "/content/drive/MyDrive/AOD-Net/snapshot-2020-12-21_10:39:27\n",
            "/content/drive/MyDrive/AOD-Net/snapshot-2020-12-21_10:39:27Epoch:\n",
            "/content/drive/MyDrive/AOD-Net/snapshot-2020-12-21_10:39:27Epoch:0\n",
            "/content/drive/MyDrive/AOD-Net/snapshot-2020-12-21_10:39:27Epoch:0_TrainTimes:\n",
            "/content/drive/MyDrive/AOD-Net/snapshot-2020-12-21_10:39:27Epoch:0_TrainTimes:9000\n",
            "/content/drive/MyDrive/AOD-Net/snapshot-2020-12-21_10:39:27Epoch:0_TrainTimes:9000.pth\n",
            "Loss at index_ 80 / 216 :iteration_ 23 : 0.6674569845199585\n",
            "Loss at index_ 100 / 216 :iteration_ 23 : 0.6684569716453552\n",
            "Loss at index_ 120 / 216 :iteration_ 23 : 0.6711931228637695\n",
            "Loss at index_ 140 / 216 :iteration_ 23 : 0.6681303381919861\n",
            "Loss at index_ 160 / 216 :iteration_ 23 : 0.649083137512207\n",
            "Loss at index_ 180 / 216 :iteration_ 23 : nan\n",
            "Loss at index_ 200 / 216 :iteration_ 23 : nan\n",
            "Loss at index_ 20 / 150 :iteration_ 24 : 0.6666666865348816\n",
            "Loss at index_ 40 / 150 :iteration_ 24 : 0.6666666865348816\n",
            "Loss at index_ 60 / 150 :iteration_ 24 : nan\n",
            "Loss at index_ 80 / 150 :iteration_ 24 : 0.6666666865348816\n",
            "Loss at index_ 100 / 150 :iteration_ 24 : 0.6666666865348816\n",
            "Loss at index_ 120 / 150 :iteration_ 24 : nan\n",
            "Loss at index_ 140 / 150 :iteration_ 24 : nan\n",
            "Loss at index_ 20 / 220 :iteration_ 25 : nan\n",
            "Loss at index_ 40 / 220 :iteration_ 25 : nan\n",
            "Loss at index_ 60 / 220 :iteration_ 25 : nan\n",
            "Loss at index_ 80 / 220 :iteration_ 25 : nan\n",
            "Loss at index_ 100 / 220 :iteration_ 25 : nan\n",
            "Loss at index_ 120 / 220 :iteration_ 25 : nan\n",
            "Loss at index_ 140 / 220 :iteration_ 25 : nan\n",
            "Loss at index_ 160 / 220 :iteration_ 25 : nan\n",
            "Loss at index_ 180 / 220 :iteration_ 25 : nan\n",
            "Loss at index_ 200 / 220 :iteration_ 25 : nan\n",
            "Loss at index_ 220 / 220 :iteration_ 25 : nan\n",
            "Loss at index_ 20 / 114 :iteration_ 26 : 0.6667777895927429\n",
            "Loss at index_ 40 / 114 :iteration_ 26 : 0.6670384407043457\n",
            "Loss at index_ 60 / 114 :iteration_ 26 : 0.6666398048400879\n",
            "Loss at index_ 80 / 114 :iteration_ 26 : 0.6666464805603027\n",
            "Loss at index_ 100 / 114 :iteration_ 26 : nan\n",
            "Loss at index_ 20 / 360 :iteration_ 27 : nan\n",
            "Loss at index_ 40 / 360 :iteration_ 27 : nan\n",
            "Loss at index_ 60 / 360 :iteration_ 27 : nan\n",
            "Loss at index_ 80 / 360 :iteration_ 27 : nan\n",
            "Loss at index_ 100 / 360 :iteration_ 27 : nan\n",
            "Loss at index_ 120 / 360 :iteration_ 27 : nan\n",
            "Loss at index_ 140 / 360 :iteration_ 27 : nan\n",
            "Loss at index_ 160 / 360 :iteration_ 27 : nan\n",
            "Loss at index_ 180 / 360 :iteration_ 27 : nan\n",
            "Loss at index_ 200 / 360 :iteration_ 27 : nan\n",
            "Loss at index_ 220 / 360 :iteration_ 27 : nan\n",
            "Loss at index_ 240 / 360 :iteration_ 27 : nan\n",
            "Loss at index_ 260 / 360 :iteration_ 27 : nan\n",
            "Loss at index_ 280 / 360 :iteration_ 27 : nan\n",
            "Loss at index_ 300 / 360 :iteration_ 27 : nan\n",
            "Loss at index_ 320 / 360 :iteration_ 27 : nan\n",
            "Loss at index_ 340 / 360 :iteration_ 27 : nan\n",
            "Loss at index_ 360 / 360 :iteration_ 27 : nan\n",
            "Loss at index_ 20 / 220 :iteration_ 28 : nan\n",
            "Loss at index_ 40 / 220 :iteration_ 28 : nan\n",
            "Loss at index_ 60 / 220 :iteration_ 28 : nan\n",
            "Loss at index_ 80 / 220 :iteration_ 28 : nan\n",
            "Loss at index_ 100 / 220 :iteration_ 28 : nan\n",
            "Loss at index_ 120 / 220 :iteration_ 28 : nan\n",
            "Loss at index_ 140 / 220 :iteration_ 28 : nan\n",
            "Loss at index_ 160 / 220 :iteration_ 28 : nan\n",
            "Loss at index_ 180 / 220 :iteration_ 28 : nan\n",
            "Loss at index_ 200 / 220 :iteration_ 28 : nan\n",
            "Loss at index_ 220 / 220 :iteration_ 28 : nan\n",
            "Loss at index_ 20 / 300 :iteration_ 29 : 0.8100263476371765\n",
            "Loss at index_ 40 / 300 :iteration_ 29 : 0.8011759519577026\n",
            "Loss at index_ 60 / 300 :iteration_ 29 : 0.6666666865348816\n",
            "Loss at index_ 80 / 300 :iteration_ 29 : 0.6666666865348816\n",
            "Loss at index_ 100 / 300 :iteration_ 29 : 0.6666666865348816\n",
            "Loss at index_ 120 / 300 :iteration_ 29 : 0.6666666865348816\n",
            "Loss at index_ 140 / 300 :iteration_ 29 : 0.6666666865348816\n",
            "Loss at index_ 160 / 300 :iteration_ 29 : 0.6666666865348816\n",
            "Loss at index_ 180 / 300 :iteration_ 29 : 0.6666666865348816\n",
            "Loss at index_ 200 / 300 :iteration_ 29 : 0.6666666865348816\n",
            "Loss at index_ 220 / 300 :iteration_ 29 : 0.6666666865348816\n",
            "Loss at index_ 240 / 300 :iteration_ 29 : 0.6666666865348816\n",
            "Loss at index_ 260 / 300 :iteration_ 29 : 0.6666666865348816\n",
            "Loss at index_ 280 / 300 :iteration_ 29 : 0.6666666865348816\n",
            "Loss at index_ 300 / 300 :iteration_ 29 : nan\n",
            "Loss at index_ 20 / 360 :iteration_ 30 : nan\n",
            "Loss at index_ 40 / 360 :iteration_ 30 : nan\n",
            "Loss at index_ 60 / 360 :iteration_ 30 : nan\n",
            "Loss at index_ 80 / 360 :iteration_ 30 : nan\n",
            "Loss at index_ 100 / 360 :iteration_ 30 : nan\n",
            "Loss at index_ 120 / 360 :iteration_ 30 : nan\n",
            "Loss at index_ 140 / 360 :iteration_ 30 : nan\n",
            "Loss at index_ 160 / 360 :iteration_ 30 : nan\n",
            "Loss at index_ 180 / 360 :iteration_ 30 : nan\n",
            "Loss at index_ 200 / 360 :iteration_ 30 : nan\n",
            "Loss at index_ 220 / 360 :iteration_ 30 : nan\n",
            "Loss at index_ 240 / 360 :iteration_ 30 : nan\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CjnhXm_O_Orm"
      },
      "source": [
        "!cp -R ./epochs/ ../drive/My\\ Drive/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_3OnrRRAGY8"
      },
      "source": [
        "!cp -R ./training_results ../drive/My\\ Drive/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QEbQ4DAFG0cl"
      },
      "source": [
        "!cp -R ./training_results ../drive/My\\ Drive/"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}